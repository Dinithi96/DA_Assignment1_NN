# -*- coding: utf-8 -*-
"""V2_IS4003_Assignment_01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oh7-4gog5tsrrXBb0DVCMYYpHyagEzc3
"""

from google.colab import files
uploaded = files.upload()

import tensorflow as tf
import pandas as pd
import io
import numpy as np
df_trn = pd.read_excel(io.BytesIO(uploaded['IS4003_SCS4104_CS4104_dataset.xlsx']), sheet_name='Training Dataset', na_values=['?'])
df_tst = pd.read_excel(io.BytesIO(uploaded['IS4003_SCS4104_CS4104_dataset.xlsx']), sheet_name='Testing Dataset', na_values=['?'])

#Check for number of data points with null values
df_trn.isna().sum()

#Pre-processing
df_trn['Gender'].replace(['Male', 'Female'], [1., -1.], inplace=True)
df_tst['Gender'].replace(['Male', 'Female'], [1., -1.], inplace=True)

df_trn['Class'].replace(['Yes', 'No'], [1., 0.], inplace=True)
df_tst['Class'].replace(['Yes', 'No'], [1., 0.], inplace=True)

means = df_tst.mean()
for col in ['Age', 'TB', 'DB', 'ALK',	'SGPT',	'SGOT',	'TP',	'ALB', 'AG_Ratio']:
    df_trn[col].fillna(means[col], inplace=True)
    df_tst[col].fillna(means[col], inplace=True)

df_trn

#Up-sampling to make the unbalnced dataset balanced
class_low = df_trn["Class"] == 0
df_trn_copy = df_trn[class_low]

df_trn = df_trn.append(df_trn_copy, ignore_index=True)

df_trn

# Shuffle
df_trn = df_trn.sample(frac=1)

X_train = df_trn[['Age', 'Gender', 'TB', 'DB', 'ALK',	'SGPT',	'SGOT',	'TP',	'ALB', 'AG_Ratio']]
y_train = df_trn['Class']
X_test = df_tst[['Age', 'Gender', 'TB', 'DB', 'ALK',	'SGPT',	'SGOT',	'TP',	'ALB', 'AG_Ratio']]
y_test = df_tst['Class']

X_train.head()

y_train.head()

#Defining the Dropout object
from tensorflow.keras.layers import Dropout

tf.keras.layers.Dropout(
    0.5, )

#Creation of the neural network model
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(10,)),
    tf.keras.layers.Dense(64, activation=tf.nn.relu),
	  tf.keras.layers.Dense(64, activation=tf.nn.relu),
    tf.keras.layers.Dense(64, activation=tf.nn.relu),
	  tf.keras.layers.Dense(20, activation=tf.nn.relu),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid),
])

#Execution of the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(X_train, y_train, validation_split=0.2, epochs=500,verbose=1)
test_loss, test_acc = model.evaluate(X_test, y_test)

test_loss, test_acc

#Model loss 
from matplotlib import pyplot

pyplot.plot(history.history['loss'])
pyplot.plot(history.history['val_loss'])
pyplot.title('model loss')
pyplot.ylabel('loss')
pyplot.xlabel('epoch')
pyplot.legend(['train', 'val'], loc='upper left')
pyplot.show()

y_preds = model.predict(X_test)

y_pred = np.round(y_preds)

#Confusion Matrix
from sklearn import metrics
from sklearn.metrics import confusion_matrix

confusion_mtx = metrics.confusion_matrix(y_test,y_pred)
print(confusion_mtx)

TN = confusion_mtx[0,0]
FP = confusion_mtx[0,1]
FN = confusion_mtx[1,0]
TP = confusion_mtx[1,1]

#Calculation of accuracy
accuracy = (TP + TN) / float(TP + TN + FP + FN)
print(accuracy)

#Calculation of accuracy score
import sklearn.metrics
from sklearn.metrics import accuracy_score

sklearn.metrics.accuracy_score(y_test, y_pred.round(), normalize=False)

#Calculation of precision
from sklearn.metrics import precision_score

precision_score(y_test, y_pred.round())

precision = TP / float(TP + FP)
print(precision)

#Calculation of sensitivity
sensitivity = TP / float(FN + TP)
print(sensitivity)

#Calculation of specificity
specificity = TN / (TN + FP)
print(specificity)

#Calculation of Error Rate
error_rate = (FP + FN) / float(TP + TN + FP + FN)
print(error_rate)

#Clasification Report
# from sklearn.metrics import classification_report
# print(classification_report(y_test, y_pred, target_names=['Yes','No']))